import pandas as pd
from pathlib import Path
import os


# --- PART 1: AUTO-SETUP (Creates the test data) ---
def setup_test_environment():
# defines a function to create test files and folders
    """
    creates a sample folder and CSV file for testing.
    
    this function generates a directory named 'temperatures'
    and stores a CSV file containing example weather data.
    """
    folder = Path("temperatures")
    # creates a path object for temperatures folder

    folder.mkdir(exist_ok=True)
    # creates the folder if it does not already exist
    
    # Create a sample CSV file
    csv_data = """Date,Station,Temperature
2025-01-15,Station_A,32.5
2025-01-15,Station_B,30.1
2025-04-12,Station_A,22.1
2025-07-20,Station_A,12.5
2025-10-05,Station_B,28.5
2025-12-25,Station_A,35.2"""

    with open(folder / "weather_2025.csv", "w") as f:
    # opens csv file in write mode
        f.write(csv_data)
        # writes data into the csv file
    print("Test folder and CSV created.")

# --- PART 2: YOUR ANALYSIS CODE ---
def process_climate_records():
# defines function to analyze climate data
    """
    it reads climate CSV files and performs temperature analysis.
    
    the function calculates seasonal averages, temperature ranges
    for each station, and identifies stable and unstable stations.
    Results are saved into text files.
    """
    target_dir = Path("temperatures")
    # sets path for data folder
    all_csv_files = list(target_dir.glob("*.csv"))
    # collects all csv files in folder

    if not all_csv_files:
    # checks if no csv files are found
        print("Alert: No data files located.")
        return

    record_stack = [pd.read_csv(f) for f in all_csv_files]
    # reads all csv files into list

    master_table = pd.concat(record_stack, ignore_index=True)
    # combines all dataframes

    clean_records = master_table.dropna(subset=['Temperature']).copy()
    # removes empty temps

    clean_records['Date'] = pd.to_datetime(clean_records['Date'])
    # converts date column

# Seasonal Mapping
season_map = {12:'Summer', 1:'Summer', 2:'Summer', 3:'Autumn', 4:'Autumn', 
                  5:'Autumn', 6:'Winter', 7:'Winter', 8:'Winter', 9:'Spring', 10:'Spring', 11:'Spring'}
clean_records['Period'] = clean_records['Date'].dt.month.map(season_map)

 # 1. Seasonal Average
    periodic_means = clean_records.groupby('Period')['Temperature'].mean()
    # average per season

    with open('average_temp.txt', 'w') as f:
    # opens text file for writing results
        for label in ['Summer', 'Autumn', 'Winter', 'Spring']:

        #loops through  season
            if label in periodic_means:
            # checks if season exists in data
                f.write(f"{label}: {periodic_means[label]:.1f}째C\n")
                # writes average value

 # 2. Temperature Range
    site_stats = clean_records.groupby('Station')['Temperature'].agg(['max', 'min'])
    # max/min
    site_stats['Span'] = site_stats['max'] - site_stats['min']
    # calculates temperature range
    peak_span = site_stats['Span'].max()
    # finds the largest temperaturerange
    widest_spread = site_stats[site_stats['Span'] == peak_span]
    # filters station with max range
    
    with open('largest_temp_range_station.txt', 'w') as f:  
    # opens file for writing
        for site_id, stats in widest_spread.iterrows():
        # loops through station data
            f.write(f"Station {site_id}: Range {stats['Span']:.1f}째C\n")
            # writes result

 # 3. Stability
    volatility = clean_records.groupby('Station')['Temperature'].std()
    # calculates std dev
    with open('temperature_stability_stations.txt', 'w') as f:
    # opens output file
        f.write(f"Most Stable: Station {volatility.idxmin()}: StdDev {volatility.min():.1f}째C\n")
        # stable station
        f.write(f"Most Variable: Station {volatility.idxmax()}: StdDev {volatility.max():.1f}째C\n")
        # variable station

    print("Analysis complete! Check the .txt files in the file sidebar.")



